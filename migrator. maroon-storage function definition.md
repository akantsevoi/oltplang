- [!] Right now I have some problem to clearly separate maroon-engine itself and storage layer. So sometimes I use words migrator-storage/maroon-storage/maroon-engine interchangeably, it is not always clear yet where is the storage function and where is it execution engine function. **Keep that in mind while reading**

## Problem
- provide consistent(invariants satisfaction) and durable storage built on top of different storage solutions presented in the organization
	- we need to solve that problem in order to open a possibility to write simpler/durable code/logic/scenarios/etc (maroon-engine)

## Function
- maroon-storage works as a black box for (business-logic developer)::role
- can use various repositories 
	- repository - external DB or any other storage that supports some API and provides some guarantees (some - TBD)
- support ACID transactions
	- A
		- all updates are done or none
	- C
		- invariants are satisfied(across different repositories)
	- I
		- since we'll have sequential read/writes - it's not relevant for migrator
		- [!] fine only until we're "single-threaded"
	- D
		- set of data as durable as repository is durable(if some repository owns some subset of data - we're limited by this repository's durability)
- admin::role can configure maroon-storage to use different repositories
	- we need to clearly specify external repositories as our direction right now is to keep the customers data in their DBs
	- different or the same types of objects can live in the same or different repositories. Examples:
		- all the data in one storage
		- part of users live in mongo and part in postgresql and some special users can be created only in that AzureDB in that region due to regulations or whatever
	- admin can also add/remove repositories at "any" time
		- "any" - of course not any time, but almost. Limitations TBD
	- admin can change the parameters of repositories and maroon-engine will migrate the data between repositories accordingly
- takes an exclusive rights on read/write operations in all connected repositories
	- all the traffic goes through the maroon-engine
- supported operations for the user
	- read object of a type by id
	- update(whole object or some fields) object of a type by id
	- create object of a type with id
	- autogenerated id
	- query by some query parameters

## Implementation thoughts
### Configuration language
- declarative approach
- strong type system

```python
storage(
	types(
		User(
			v1(
				id int
				name string
				country string
			), 
			v2(
				id int
				name string
				country string
				active bool
			)
			migration(
				// since new field is non-optional we need to add some code that can perform the transition between v1 and v2
				// underthehood engine will do the heavylifting:
				//   - introduce a new `active` optional field
				//   - starts updating value of the field
				//   - when finishes - it will move the column from optional to non-optional state
				to_v2(obj: v1) -> v2 { 
					is_active := http.call.is_active(obj.id)
					return v2{
						active: is_active,
						v1...}
				}
			)
		)
	)
	repositories (
		mongodb(
			id: "eu-users-repository",
			connectionParams: {bla bla},
			 holdTypes(
				 User.v1(
					 id -> users.id, // mapping between in-memory object and table/field in a table datastore
					 name -> users.name,
					 country -> users.country,
				 ),
				 User.v2(
					 id -> users.id,
					 name -> users.name,
					 country -> users.country,
					 active -> users.active
				 ),
			 )
		),
		postgresql(
			id: "eu-users-repository-new", // imagine that we're migrating users from mongodb to postgres(unified storing approach), but it still should be in some EU-based DC
			connectionParams: {...},
			 holdTypes(
				 User.v1(
					 id -> users.id,
					 name -> users.name,
					 country -> users_meta.country (foreing_key: users.id), // compound object that lives in different tables
				 ),
				 User.v2(
					 id -> users.id,
					 name -> users.name,
					 country -> users_meta.country (foreing_key: users.id),
					 active -> users.active,
				 ),
			 )
		),
		postgresql(
			id: "us-users-repository",
			connectionParams: {...},
			 holdTypes(
				 User.v1(
					 id -> users.id,
					 name -> users.name,
					 country -> users_meta.country (foreing_key: users.id),
				 ),
				 User.v2(
					 id -> users.id,
					 name -> users.name,
					 country -> users_meta.country (foreing_key: users.id),
					 active -> users.active,
				 ),
			 )
		)
	),
	location_rules(
		priority_migration(
			// in that case data will be slowly copied from one storage to another
			// TODO: we need to have a requirement here that transformation should cover all the fields and it should be checked
			"eu-users-repository" ==> "eu-users-repository-new"
		)
		User.v1(country == "USA" => "us-users-repository"),
		User.v2(country == "USA" => "us-users-repository"),
		User.v1(country == "UK" => ["eu-users-repository", "eu-users-repository-new"]),
		User.v2(country == "UK" => ["eu-users-repository", "eu-users-repository-new"]),
	)
)
```

### Internal structure

two parts of migrator's maroon-storage:
- maroon-storage aka source-of-truth on each maroon node
	- stores:
		- id, type, version
			- [?] what is id here? Is it internal maroon-storage's id? What about ids in repositories? Do we treat them as a piece of data or secondary id or what?
		- hash(for last n versions and/or last n hours)
			- in case of 
		- logs of transition between versions: n and n-1
	- functions:
		- indexes for querying
			- [?] how to query effectively the data from different repositories? (do we need to open a conversation of creating indexes in the maroon-storage?)
- repositories
	- any storage that can support the contract:
		- R/W/U/D operations
		- strong types (not abstract JSON storage)
			- [?] do we really need this guarantee? Isn't enough to keep type information inside of maroon-storage?
